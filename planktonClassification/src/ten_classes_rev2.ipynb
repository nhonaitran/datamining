{
 "metadata": {
  "name": "",
  "signature": "sha256:98878c7623eeec959f165b3a27f35bf93564e7540d97c0eea9a6c3cb310187a9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.io import imread\n",
      "from skimage.transform import resize\n",
      "from sklearn.ensemble import RandomForestClassifier as RF\n",
      "import glob\n",
      "import os\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "from sklearn.metrics import classification_report\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import colors\n",
      "from pylab import cm\n",
      "from skimage import segmentation\n",
      "from skimage.morphology import watershed\n",
      "from skimage import measure\n",
      "from skimage import morphology\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import ndimage\n",
      "from skimage.feature import peak_local_max\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "import cv2\n",
      "import cv2.cv as cv\n",
      "import random\n",
      "\n",
      "from scipy.cluster.vq import *\n",
      "from sklearn.preprocessing import StandardScaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ~/git/datamining/Kaggle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/nhonaitran/git/datamining/Kaggle\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the classnames from the directory structure\n",
      "dirs = list(set(glob.glob(os.path.join(\"Data\",\"train\", \"*\"))).difference(set(glob.glob(os.path.join(\"Data\",\"train\",\"*.*\")))))\n",
      "dirs.sort()\n",
      "print \"total # of classes:\", len(dirs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total # of classes: 121\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_k = 10\n",
      "directory_names = dirs[0:top_k]\n",
      "#directory_names=dirs\n",
      "print \"total # of classes under study:\", len(directory_names)\n",
      "print directory_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total # of classes under study: 10\n",
        "['Data/train/acantharia_protist', 'Data/train/acantharia_protist_big_center', 'Data/train/acantharia_protist_halo', 'Data/train/amphipods', 'Data/train/appendicularian_fritillaridae', 'Data/train/appendicularian_s_shape', 'Data/train/appendicularian_slight_curve', 'Data/train/appendicularian_straight', 'Data/train/artifacts', 'Data/train/artifacts_edge']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find the largest nonzero region\n",
      "def getLargestRegion(props, labelmap, imagethres):\n",
      "    regionmaxprop = None\n",
      "    for regionprop in props:\n",
      "        # check to see if the region is at least 50% nonzero\n",
      "        if sum(imagethres[labelmap == regionprop.label])*1.0/regionprop.area < 0.50:\n",
      "            continue\n",
      "        if regionmaxprop is None:\n",
      "            regionmaxprop = regionprop\n",
      "        if regionmaxprop.filled_area < regionprop.filled_area:\n",
      "            regionmaxprop = regionprop\n",
      "    return regionmaxprop\n",
      "\n",
      "def getGlobalFeatures(image):\n",
      "    image = image.copy()\n",
      "    \n",
      "    # thresholding the image on the the mean value\n",
      "    # to reduce noise in the image, eliminate some of the background\n",
      "    imagethr = np.where(image > np.mean(image),0.,1.0)\n",
      "\n",
      "    # dilate the image to connect neighboring pixels\n",
      "    imdilated = morphology.dilation(imagethr, np.ones((4,4)))\n",
      "\n",
      "    # alculate the labels for connected regions Create the label list\n",
      "    label_list = measure.label(imdilated)\n",
      "    label_list = imagethr*label_list\n",
      "    label_list = label_list.astype(int)\n",
      "    \n",
      "    region_list = measure.regionprops(label_list)\n",
      "    maxregion = getLargestRegion(region_list, label_list, imagethr)\n",
      "    \n",
      "    # guard against cases where the segmentation fails by providing zeros\n",
      "    filled_area = 0.0\n",
      "    perimeter = 0.0\n",
      "    ratio = 0.0\n",
      "    compactness = 0.0\n",
      "    moments=np.zeros([7,1])\n",
      "    if (not maxregion is None):\n",
      "        if ((maxregion.major_axis_length != 0.0)):\n",
      "            ratio = maxregion.minor_axis_length*1.0 / maxregion.major_axis_length\n",
      "        \n",
      "        no_of_pixels_in_region = maxregion.area\n",
      "        if (no_of_pixels_in_region == 0.0):\n",
      "            no_of_pixels_in_region = 0.0001  # do this to prevent divide-by-zero when calc compactness\n",
      "            \n",
      "        filled_area = maxregion.filled_area\n",
      "        perimeter = maxregion.perimeter\n",
      "        compactness = perimeter * perimeter / no_of_pixels_in_region\n",
      "        moments = maxregion.moments_hu\n",
      "    return(compactness, filled_area, perimeter, ratio, moments)\n",
      "    \n",
      "def getFeaturesUsingSIFT(k = 12):\n",
      "    des_list=[]\n",
      "    # Navigate through the list of directories\n",
      "    for folder in directory_names:\n",
      "        for fileNameDir in os.walk(folder):   \n",
      "            for fileName in fileNameDir[2]:\n",
      "                # Only read in the images\n",
      "                if fileName[-4:] != \".jpg\":\n",
      "                  continue\n",
      "\n",
      "                # Read in the images and create the features\n",
      "                nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "                image = imread(nameFileImage, as_grey=True)    \n",
      "\n",
      "                sift = cv2.SIFT()\n",
      "                kp, des = sift.detectAndCompute(image,None)\n",
      "                if (des==None):\n",
      "                    des=np.array([[0]*128])\n",
      "                des_list.append(des)\n",
      "    \n",
      "    \n",
      "    \n",
      "    # Using Bag of Words (Visual Words) model \n",
      "    # for having same size of features per image\n",
      "    \n",
      "    descriptors =[]\n",
      "    descriptors = np.vstack(des_list) \n",
      "\n",
      "    # Perform k-means clustering\n",
      "    #k = 12\n",
      "    voc, variance = kmeans(descriptors, k, 1) \n",
      "\n",
      "    # Calculate the histogram of features\n",
      "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
      "    for i in xrange(len(des_list)):\n",
      "        words, distance = vq(des_list[i],voc)\n",
      "        for w in words:\n",
      "            im_features[i][w] += 1\n",
      "\n",
      "    # Scaling the words\n",
      "    stdSlr = StandardScaler().fit(im_features)\n",
      "    im_features = stdSlr.transform(im_features)\n",
      "    # im_features has k columns with the number of image rows\n",
      "    # because we clustered all the descriptors (for all images) into k clusters\n",
      "    # and the feature for each image will be histogram of theses clusters\n",
      "    # meaning that each image has k features that each feature is the number of \n",
      "    # descriptors that are belonged to that cluster. \n",
      "\n",
      "    #return(features)\n",
      "    return(im_features)\n",
      "\n",
      "\n",
      "def getFeaturesUsingSURF(k = 12):\n",
      "    des_list=[]\n",
      "    # Navigate through the list of directories\n",
      "    for folder in directory_names:\n",
      "        for fileNameDir in os.walk(folder):   \n",
      "            for fileName in fileNameDir[2]:\n",
      "                # Only read in the images\n",
      "                if fileName[-4:] != \".jpg\":\n",
      "                  continue\n",
      "\n",
      "                # Read in the images and create the features\n",
      "                nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "                image = imread(nameFileImage, as_grey=True)    \n",
      "\n",
      "                surf = cv2.SURF(400)\n",
      "                kp, des = surf.detectAndCompute(image,None)\n",
      "                if (des==None):\n",
      "                    des=np.array([[0]*128])\n",
      "                des_list.append(des)\n",
      "    \n",
      "    \n",
      "    \n",
      "    # Using Bag of Words (Visual Words) model \n",
      "    # for having same size of features per image\n",
      "    \n",
      "    descriptors =[]\n",
      "    descriptors = np.vstack(des_list) \n",
      "\n",
      "    # Perform k-means clustering\n",
      "    #k = 12\n",
      "    voc, variance = kmeans(descriptors, k, 1) \n",
      "\n",
      "    # Calculate the histogram of features\n",
      "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
      "    for i in xrange(len(des_list)):\n",
      "        words, distance = vq(des_list[i],voc)\n",
      "        for w in words:\n",
      "            im_features[i][w] += 1\n",
      "\n",
      "    # Scaling the words\n",
      "    stdSlr = StandardScaler().fit(im_features)\n",
      "    im_features = stdSlr.transform(im_features)\n",
      "    # im_features has k columns with the number of image rows\n",
      "    # because we clustered all the descriptors (for all images) into k clusters\n",
      "    # and the feature for each image will be histogram of theses clusters\n",
      "    # meaning that each image has k features that each feature is the number of \n",
      "    # descriptors that are belonged to that cluster. \n",
      "\n",
      "    #return(features)\n",
      "    return(im_features)    \n",
      "\n",
      "\n",
      "\n",
      "def getFeaturesUsingORB(k = 12):\n",
      "    des_list=[]\n",
      "    # Navigate through the list of directories\n",
      "    for folder in directory_names:\n",
      "        for fileNameDir in os.walk(folder):   \n",
      "            for fileName in fileNameDir[2]:\n",
      "                # Only read in the images\n",
      "                if fileName[-4:] != \".jpg\":\n",
      "                  continue\n",
      "\n",
      "                # Read in the images and create the features\n",
      "                nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "                image = imread(nameFileImage, as_grey=True)    \n",
      "\n",
      "                orb = cv2.ORB()\n",
      "                kp, des = orb.detectAndCompute(image,None)\n",
      "                if (des==None):\n",
      "                    des=np.array([[0]*32])\n",
      "                des_list.append(des)\n",
      "    \n",
      "    \n",
      "    \n",
      "    # Using Bag of Words (Visual Words) model \n",
      "    # for having same size of features per image\n",
      "    \n",
      "    descriptors =[]\n",
      "    descriptors = np.vstack(des_list) \n",
      "\n",
      "    # Perform k-means clustering\n",
      "    #k = 12\n",
      "    voc, variance = kmeans(descriptors, k, 1) \n",
      "\n",
      "    # Calculate the histogram of features\n",
      "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
      "    for i in xrange(len(des_list)):\n",
      "        words, distance = vq(des_list[i],voc)\n",
      "        for w in words:\n",
      "            im_features[i][w] += 1\n",
      "\n",
      "    # Scaling the words\n",
      "    stdSlr = StandardScaler().fit(im_features)\n",
      "    im_features = stdSlr.transform(im_features)\n",
      "    # im_features has k columns with the number of image rows\n",
      "    # because we clustered all the descriptors (for all images) into k clusters\n",
      "    # and the feature for each image will be histogram of theses clusters\n",
      "    # meaning that each image has k features that each feature is the number of \n",
      "    # descriptors that are belonged to that cluster. \n",
      "\n",
      "    #return(features)\n",
      "    return(im_features)\n",
      "\n",
      "#def getCircles(image, filename, param1=50,param2=30,minRadius=1,maxRadius=100, showimage=True):\n",
      "#    if (showimage):\n",
      "#        sub1 = plt.subplot(1,2,1)\n",
      "#        plt.imshow(image)\n",
      "#        sub1.set_title(fileName)\n",
      "\n",
      "#    gray = imread(fileImage, as_grey=True)    \n",
      "    \n",
      "#    kernel_size = 5\n",
      "#    # smooth image to reduce the number of false positives\n",
      "#    img_smooth = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
      "    \n",
      "#    circles = cv2.HoughCircles(gray,cv.CV_HOUGH_GRADIENT,1,20,param1,param2,minRadius,maxRadius)\n",
      "#    if (circles == None):\n",
      "#        no_of_circles = 0\n",
      "#    else:\n",
      "#        circles = np.uint16(np.around(circles))\n",
      "#        no_of_circles = len(circles)\n",
      "#        img = image.copy()\n",
      "#        if (showimage):\n",
      "#            for i in circles[0,:]:\n",
      "#                # draw the outer circle\n",
      "#                cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)\n",
      "#                # draw the center of the circle\n",
      "#                cv2.circle(img,(i[0],i[1]),2,(0,0,255),3)\n",
      "#               \n",
      "#     return(no_of_circles)\n",
      "                \n",
      "def getCornerFeatures(image, filename, maxCorners=25, qualityLevel=0.01, minDistance=10, showimage=True):\n",
      "    radius = 2\n",
      "    color = (0,0,0) #(255,255,255) #white color, (0,0,0)=black color\n",
      "    thickness = -1 #thickness of the circle outline, if positive. \n",
      "                  #negative thickness means that a filled circle is to be drawn.\n",
      "    if (showimage):\n",
      "        sub1 = plt.subplot(1,2,1)\n",
      "        plt.imshow(image)\n",
      "        sub1.set_title(fileName)\n",
      "\n",
      "    gray = imread(filename, as_grey=True)\n",
      "    corners = cv2.goodFeaturesToTrack(gray, maxCorners, qualityLevel, minDistance)\n",
      "    if (corners == None):\n",
      "        no_of_corners = 0\n",
      "        x_coord_std = 0.0\n",
      "        y_coord_std = 0.0\n",
      "    else:\n",
      "        corners = np.int0(corners)\n",
      "        no_of_corners = len(corners)\n",
      "        #print(corners) #contain x,y coordinate pairs of the corners\n",
      "        #print size(corners)\n",
      "        \n",
      "        x_coord_std = corners.std(axis=0)[0][0]\n",
      "        y_coord_std = corners.std(axis=0)[0][1]\n",
      "        \n",
      "        image2 = image.copy()\n",
      "        for corner in corners:\n",
      "            x,y = corner.ravel()\n",
      "            cv2.circle(image2, (x,y), radius, color, thickness)\n",
      "        \n",
      "        if(showimage):\n",
      "            sub2 = plt.subplot(1,2,2)\n",
      "            plt.imshow(image2)\n",
      "            sub2.set_title(\"...with corners added ({0} corners found)\".format(len(corners)))\n",
      "            plt.show()\n",
      "            \n",
      "    return(no_of_corners, x_coord_std, y_coord_std)\n",
      "                \n",
      "def computePerformance(X, y, namesClasses, cv_folds=10):\n",
      "    # parameters for SVM model selection\n",
      "    kernel = ['rbf']\n",
      "    gamma_range = 10.0 ** np.arange(-4, 2)\n",
      "    C_range = 10.0 ** np.arange(0, 4)\n",
      "    params_grid = dict(kernel=kernel, gamma=gamma_range, C=C_range)\n",
      "    #print params_grid\n",
      "\n",
      "    # find optimal hyperparameters\n",
      "    svm_models = GridSearchCV(SVC(), param_grid=params_grid, n_jobs=-1).fit(X, y)\n",
      "    #for params, mean_score, scores in svm_models_2.grid_scores_:\n",
      "    #    print(\"%10.3f for %r\" % (mean_score, params))\n",
      "    best_c = svm_models.best_params_['C']\n",
      "    best_gamma = svm_models.best_params_['gamma']\n",
      "    print svm_models.best_params_\n",
      "\n",
      "    # compute overall accuracy\n",
      "    fit = SVC(kernel='rbf', C=best_c, gamma=best_gamma)\n",
      "    scores_all = cross_validation.cross_val_score(fit, X, y, cv=cv_folds, n_jobs=-1);\n",
      "    print \"Accuracy of all classes\"\n",
      "    print np.mean(scores_all)\n",
      "    \n",
      "    # compute CV accuracy per class\n",
      "    kf = KFold(y, n_folds=cv_folds)\n",
      "    y_pred = y * 0\n",
      "    for train, test in kf:\n",
      "        X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
      "        model = SVC(kernel='rbf', C=best_c, gamma=best_gamma)\n",
      "        model.fit(X_train, y_train)\n",
      "        y_pred[test] = model.predict(X_test)\n",
      "    print classification_report(y, y_pred, target_names=namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rescale the images and create the combined metrics and training labels\n",
      "#get the total training images\n",
      "numberofImages = 0\n",
      "for folder in directory_names:\n",
      "    for fileNameDir in os.walk(folder):   \n",
      "        for fileName in fileNameDir[2]:\n",
      "             # Only read in the images\n",
      "            if fileName[-4:] != \".jpg\":\n",
      "              continue\n",
      "            numberofImages += 1\n",
      "\n",
      "# We'll rescale the images to be 25x25\n",
      "maxPixel = 25\n",
      "imageSize = maxPixel * maxPixel\n",
      "num_rows = numberofImages # one row for each image in the training dataset\n",
      "num_features = imageSize + 7 + 25 # for our ratio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# X is the feature vector with one row of features per image\n",
      "# consisting of the pixel values and our metric\n",
      "X = np.zeros((num_rows, num_features), dtype=float)\n",
      "# y is the numeric class label \n",
      "y = np.zeros((num_rows))\n",
      "\n",
      "\n",
      "\n",
      "files = []\n",
      "# Generate training data\n",
      "i = 0    \n",
      "label = 0\n",
      "# List of string of class names\n",
      "namesClasses = list()\n",
      "\n",
      "# SIFT features\n",
      "sift_features = getFeaturesUsingSIFT(k = 12)\n",
      "# SURF features\n",
      "#surf_features = getFeaturesUsingSURF(k = 12)\n",
      "# ORB features\n",
      "#orb_features = getFeaturesUsingORB(k = 12)\n",
      "\n",
      "\n",
      "\n",
      "print \"Reading images and compute features\"\n",
      "# Navigate through the list of directories\n",
      "for folder in directory_names:\n",
      "    #print folder\n",
      "    # Append the string class name for each class\n",
      "    currentClass = folder.split(os.pathsep)[-1]\n",
      "    namesClasses.append(currentClass)\n",
      "    for fileNameDir in os.walk(folder):   \n",
      "        for fileName in fileNameDir[2]:\n",
      "            # Only read in the images\n",
      "            if fileName[-4:] != \".jpg\":\n",
      "              continue\n",
      "            \n",
      "            # Read in the images and create the features\n",
      "            nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "            image = imread(nameFileImage, as_grey=True)\n",
      "            no_of_corners, corners_x_coord_std, corners_y_coord_std = getCornerFeatures(image, nameFileImage, showimage=False)\n",
      "            \n",
      "\n",
      "            files.append(nameFileImage)\n",
      "            image = resize(image, (maxPixel, maxPixel))\n",
      "            \n",
      "            # store the rescaled image pixels and the axis ratio\n",
      "            X[i, 0:imageSize] = np.reshape(image, (1, imageSize))\n",
      "            \n",
      "            # global features\n",
      "            compactness, area, perimeter, axisratio, moments = getGlobalFeatures(image)\n",
      "            X[i, imageSize] = compactness\n",
      "            X[i, imageSize+1] = area #filled area\n",
      "            X[i, imageSize+2] = perimeter\n",
      "            X[i, imageSize+3] = axisratio\n",
      "            \n",
      "            # corner features\n",
      "            X[i, imageSize+4] = no_of_corners\n",
      "            X[i, imageSize+5] = corners_x_coord_std\n",
      "            X[i, imageSize+6] = corners_y_coord_std            \n",
      "            X[i, imageSize+7] = moments[0]\n",
      "            X[i, imageSize+8] = moments[1]\n",
      "            X[i, imageSize+9] = moments[2]\n",
      "            X[i, imageSize+10] = moments[3]\n",
      "            X[i, imageSize+11] = moments[4]\n",
      "            X[i, imageSize+12] = moments[5]\n",
      "            X[i, imageSize+13] = moments[6]\n",
      "            # adding SIFT features         \n",
      "            X[i, imageSize+13:imageSize+25] = sift_features[i,]\n",
      "            \n",
      "            # adding SURF features    \n",
      "            #X[i, imageSize+25:imageSize+37] = surf_features[i,]\n",
      "            \n",
      "            # adding ORB features      \n",
      "            #X[i, imageSize+37:imageSize+49] = orb_features[i,]\n",
      "            \n",
      "            # Store the classlabel\n",
      "            y[i] = label\n",
      "            i += 1\n",
      "            # report progress for each 5% done  \n",
      "            report = [int((j+1)*num_rows/20.) for j in range(20)]\n",
      "            if i in report: print np.ceil(i *100.0 / num_rows), \"% done\"\n",
      "    label += 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading images and compute features\n",
        "5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "10.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "15.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "20.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "25.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "30.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "35.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "40.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "45.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "50.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "55.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "60.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "65.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "70.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "75.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "80.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "85.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "90.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "95.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "100.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/nhonaitran/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/skimage/util/dtype.py:107: UserWarning: Possible precision loss when converting from float64 to uint8\n",
        "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification performance using raw pixel of image as features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 657) (3071,)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[5:,0:imageSize]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
        " [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
        " [ 1.          1.          1.         ...,  0.99990588  1.          1.        ]\n",
        " ..., \n",
        " [ 0.99691294  0.99898353  0.99628235 ...,  0.91987451  0.93888627\n",
        "   0.95715765]\n",
        " [ 1.          0.99887059  0.99952941 ...,  1.          0.98123922\n",
        "   0.93032157]\n",
        " [ 0.99351529  0.98484706  0.9377098  ...,  0.888       0.75230745\n",
        "   0.14870275]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,0:imageSize], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.10000000000000001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.778162308715\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.91      0.96      0.93       889\n",
        "Data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      Data/train/acantharia_protist_halo       0.72      0.46      0.56        71\n",
        "                    Data/train/amphipods       0.97      0.61      0.75        49\n",
        "Data/train/appendicularian_fritillaridae       0.25      0.06      0.10        16\n",
        "      Data/train/appendicularian_s_shape       0.73      0.76      0.74       696\n",
        " Data/train/appendicularian_slight_curve       0.61      0.62      0.61       532\n",
        "     Data/train/appendicularian_straight       0.60      0.49      0.54       242\n",
        "                    Data/train/artifacts       0.88      0.90      0.89       393\n",
        "               Data/train/artifacts_edge       0.77      0.84      0.80       170\n",
        "\n",
        "                             avg / total       0.77      0.78      0.77      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using global features: compactness, filled area, perimeter, axis ratio"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize:imageSize+4].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 4)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[5:,imageSize:imageSize+4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  28.59321728   61.           41.76345597    0.62007183]\n",
        " [  42.443471     59.           50.04163056    0.68971977]\n",
        " [  38.13678878   56.           46.21320344    0.78875574]\n",
        " ..., \n",
        " [ 108.69469446  179.          138.70458146    0.79669201]\n",
        " [ 124.62222215  207.          160.22539674    0.8740351 ]\n",
        " [   0.            0.            0.            0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize:imageSize+4], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.606285467296\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.84      0.86      0.85       889\n",
        "Data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      Data/train/acantharia_protist_halo       0.14      0.01      0.03        71\n",
        "                    Data/train/amphipods       0.63      0.55      0.59        49\n",
        "Data/train/appendicularian_fritillaridae       1.00      0.06      0.12        16\n",
        "      Data/train/appendicularian_s_shape       0.45      0.70      0.55       696\n",
        " Data/train/appendicularian_slight_curve       0.33      0.25      0.28       532\n",
        "     Data/train/appendicularian_straight       0.47      0.06      0.11       242\n",
        "                    Data/train/artifacts       0.73      0.70      0.72       393\n",
        "               Data/train/artifacts_edge       0.79      0.89      0.83       170\n",
        "\n",
        "                             avg / total       0.59      0.61      0.58      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features (corners)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+4:imageSize+7].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 3)\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+4:imageSize+7])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  5.           8.61162006  11.88276062]\n",
        " [ 11.          18.42160069  20.89287909]\n",
        " [  6.          12.61502631   9.01387819]\n",
        " ..., \n",
        " [ 11.           8.84485189  13.56526922]\n",
        " [ 11.           9.65178868  13.01112048]\n",
        " [ 10.          10.49571341  12.03494911]]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+4:imageSize+7], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.520486394357\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.61      0.59      0.60       889\n",
        "Data/train/acantharia_protist_big_center       0.50      0.23      0.32        13\n",
        "      Data/train/acantharia_protist_halo       0.46      0.37      0.41        71\n",
        "                    Data/train/amphipods       0.00      0.00      0.00        49\n",
        "Data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data/train/appendicularian_s_shape       0.41      0.71      0.52       696\n",
        " Data/train/appendicularian_slight_curve       0.36      0.18      0.24       532\n",
        "     Data/train/appendicularian_straight       0.54      0.10      0.17       242\n",
        "                    Data/train/artifacts       0.63      0.75      0.68       393\n",
        "               Data/train/artifacts_edge       0.81      0.76      0.78       170\n",
        "\n",
        "                             avg / total       0.51      0.52      0.49      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features : SIFT"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+13:imageSize+25].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 12)\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+13:imageSize+25])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.69969678 -0.33770549 -0.53919363 ...,  0.45665598 -0.30867371\n",
        "  -0.5596748 ]\n",
        " [-0.69969678 -0.33770549 -0.53919363 ..., -0.34425238  0.00751607\n",
        "  -0.5596748 ]\n",
        " [-0.69969678 -0.33770549 -0.53919363 ..., -0.34425238 -0.30867371\n",
        "  -0.5596748 ]\n",
        " ..., \n",
        " [-0.69969678 -0.33770549 -0.53919363 ..., -0.34425238  0.63989568\n",
        "  -0.5596748 ]\n",
        " [-0.69969678 -0.33770549 -0.53919363 ..., -0.34425238  0.00751607\n",
        "  -0.5596748 ]\n",
        " [-0.69969678 -0.33770549 -0.53919363 ..., -0.34425238  5.3827424\n",
        "  -0.5596748 ]]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+13:imageSize+25], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.636574863468\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.73      0.94      0.82       889\n",
        "Data/train/acantharia_protist_big_center       0.71      0.38      0.50        13\n",
        "      Data/train/acantharia_protist_halo       0.76      0.23      0.35        71\n",
        "                    Data/train/amphipods       0.52      0.49      0.51        49\n",
        "Data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data/train/appendicularian_s_shape       0.66      0.71      0.69       696\n",
        " Data/train/appendicularian_slight_curve       0.44      0.39      0.41       532\n",
        "     Data/train/appendicularian_straight       0.59      0.19      0.29       242\n",
        "                    Data/train/artifacts       0.50      0.58      0.54       393\n",
        "               Data/train/artifacts_edge       0.91      0.60      0.72       170\n",
        "\n",
        "                             avg / total       0.63      0.64      0.62      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features : SURF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+19:imageSize+31].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+19:imageSize+31])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+19:imageSize+31], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features : ORB"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+31:imageSize+43].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+31:imageSize+43])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+31:imageSize+43], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Raw pixel + SIFT"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_saw_sift = np.zeros([X.shape[0],imageSize+12])\n",
      "X_saw_sift[:,0:625]=X[:,0:625]\n",
      "X_saw_sift[:,625:637]=X[:,imageSize+13:imageSize+25]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X_saw_sift, y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.763490825192\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.88      0.93      0.90       889\n",
        "Data/train/acantharia_protist_big_center       0.50      0.23      0.32        13\n",
        "      Data/train/acantharia_protist_halo       0.76      0.54      0.63        71\n",
        "                    Data/train/amphipods       0.73      0.82      0.77        49\n",
        "Data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data/train/appendicularian_s_shape       0.72      0.74      0.73       696\n",
        " Data/train/appendicularian_slight_curve       0.58      0.58      0.58       532\n",
        "     Data/train/appendicularian_straight       0.61      0.52      0.56       242\n",
        "                    Data/train/artifacts       0.87      0.87      0.87       393\n",
        "               Data/train/artifacts_edge       0.88      0.88      0.88       170\n",
        "\n",
        "                             avg / total       0.76      0.76      0.76      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "C+G+M+sift"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize:imageSize+25], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.768850563515\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.88      0.95      0.91       889\n",
        "Data/train/acantharia_protist_big_center       0.58      0.54      0.56        13\n",
        "      Data/train/acantharia_protist_halo       0.83      0.70      0.76        71\n",
        "                    Data/train/amphipods       0.70      0.71      0.71        49\n",
        "Data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data/train/appendicularian_s_shape       0.72      0.76      0.74       696\n",
        " Data/train/appendicularian_slight_curve       0.52      0.57      0.54       532\n",
        "     Data/train/appendicularian_straight       0.60      0.32      0.42       242\n",
        "                    Data/train/artifacts       0.92      0.89      0.91       393\n",
        "               Data/train/artifacts_edge       0.98      0.96      0.97       170\n",
        "\n",
        "                             avg / total       0.76      0.77      0.76      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "PCA on Raw pixels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA as sklearnPCA\n",
      "sklearn_pca = sklearnPCA(50)\n",
      "X_wPCA = sklearn_pca.fit_transform(X[:,0:imageSize])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_wPCA.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "50\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "PCA on Raw+C+G+M+sift"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_new=np.zeros([X.shape[0],X_wPCA.shape[1]+26])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_new.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 76)\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_new[:,0:50]=X_wPCA\n",
      "X_new[:,51:]=X[:,imageSize:imageSize+25]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_new.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 76)\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X_new, y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.817579349435\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.92      0.96      0.94       889\n",
        "Data/train/acantharia_protist_big_center       0.50      0.46      0.48        13\n",
        "      Data/train/acantharia_protist_halo       0.84      0.72      0.77        71\n",
        "                    Data/train/amphipods       0.85      0.82      0.83        49\n",
        "Data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data/train/appendicularian_s_shape       0.75      0.79      0.77       696\n",
        " Data/train/appendicularian_slight_curve       0.64      0.63      0.63       532\n",
        "     Data/train/appendicularian_straight       0.71      0.61      0.66       242\n",
        "                    Data/train/artifacts       0.94      0.92      0.93       393\n",
        "               Data/train/artifacts_edge       0.98      0.95      0.96       170\n",
        "\n",
        "                             avg / total       0.81      0.82      0.81      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using raw pixel, local features (corner,point-based), and global feaures."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X, y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.81305757395\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data/train/acantharia_protist       0.92      0.96      0.94       889\n",
        "Data/train/acantharia_protist_big_center       0.55      0.46      0.50        13\n",
        "      Data/train/acantharia_protist_halo       0.78      0.72      0.75        71\n",
        "                    Data/train/amphipods       0.85      0.84      0.85        49\n",
        "Data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data/train/appendicularian_s_shape       0.74      0.78      0.76       696\n",
        " Data/train/appendicularian_slight_curve       0.63      0.62      0.63       532\n",
        "     Data/train/appendicularian_straight       0.70      0.58      0.63       242\n",
        "                    Data/train/artifacts       0.94      0.93      0.94       393\n",
        "               Data/train/artifacts_edge       0.97      0.95      0.96       170\n",
        "\n",
        "                             avg / total       0.81      0.81      0.81      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}