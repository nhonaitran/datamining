
In this segment, we'll introduce the probabilistic
interpretation of logistic regression.
And we'll show how this probabilistic interpretation
relates to our previous discussion on linear decision
boundaries.
We previously discussed linear classification models
and showed how various surrogate convex loss
functions can be used to approximate the 0/1 loss.
In this setting, our goal was simply
to predict one of two class labels.
However, what if we want more granular information
and, instead, want a model of a conditional probability
that a label equals 1 given some set of predictive features?
As a toy example, we might predict
whether it will rain given weather-related features
such as the temperature, cloudiness, and the humidity.
When it's cold, not cloudy, and the humidity is very low,
we might expect rain to be unlikely.
In contrast, when it's warmer, cloudy,
and when the humidity is high, we
might expect a high probability of rain.
As another example, let's consider a click-through rate
prediction problem.
And recall that we want to predict the probability
that we'll see a click event given some predictive features
about the user, the advertisement,
and the publisher page under consideration.
As a simple example, imagine that we
have three predictive features that we're working with.
The first is an ad's historical performance,
or how often the ad has been clicked in the past.
The second is the user's click rate frequency over all ads
the user has ever been presented with.
The third feature is some notion of the relevance
of the publisher's site in the context of the ad
and the user's background.
If we're considering an ad that has
good historical performance, a user that has a high click rate
frequency, and a highly relevant publisher page,
we might expect a probability to be around 0.1.
And this would suggest that there's a 10% chance
that a click event will occur.
Although this number's low on an absolute scale,
recall that click events are rare,
and thus, the probability of 0.1 is a relatively high
probability in our context.
In contrast, if the ad has bad historical performance,
the user has a low click frequency,
and the publisher page is not relevant,
we'd expect a much lower probability.
So how can we model this probability?
Our first thought might be to model
it using the standard linear regression model we
obtain via linear regression.
But of course, this isn't going to work
because the linear regression model returns a real number.
And probabilities must range between 0 and 1.
So if we want to work with a linear model,
we need to squash its output so that it'll
be in the appropriate range.
We can do this using the logistic, or sigmoid function,
which takes as input the dot product between our model
and our features and returns a value between 0 and 1,
which we can interpret as a probability.
Let's look at a plot of a logistic function
to better understand what's going on.
First note that the x-axis, or domain of this function,
is all real numbers, which is good
since we're feeding into the logistic function w transpose
x.
Second, note that the y-axis, or the range of this function,
is between 0 and 1, which is also good
because we like to interpret the output of a logistic function
as a probability.
Additionally, note that large positive inputs asymptotically
approach 1 while large negative numbers asymptotically
approach 0.

It turns out that we can interpret logistic regression
as using the logistic function to model
our conditional probability of interest.
I should note here that for the remainder of this lecture,
we'll be switching notation and assuming that labels are either
0 or 1.
We make this switch simply for notational convenience
when discussing probabilistic interpretations
of logistic regression.
Using this notation, logistic regression models
the conditional probability that a label equals 1
as the sigmoid function applied to w transpose x.
It further models the probability
that the label equals 0 as 1 minus this quantity.
And this makes sense because together,
the sum of these two probabilities should equal 1.
It can be very natural to work directly
with these class probabilities, as we'll
discuss in detail later on.
But there are also times when we want
to convert these probabilities into discrete class
predictions.
So how can we go about doing this?
A reasonable thing to do is to threshold these probabilities
with 0.5 being the default threshold.
Using thresholding, we define y hat to be equal to 1
if the conditional probability is greater than 0.5.
And we define y hat to be 0 if the probability is
less than 0.5.
When the probability exactly equals 0.5,
we can arbitrarily choose the value of y hat.
Returning to our rain example, this
would mean that when our conditional probability of rain
equals 0.05, our class prediction
would be y hat equals 0.
And when our conditional probability equals 0.9,
y hat equals 1.
It turns out that using this thresholding rule
leads to a very natural connection
with our previous discussion about decision boundaries.
Recall that we previously defined
y hat is the sine of w transpose x, which
implies that when w transpose x is greater than 0
that y hat equals 1 and when w transpose x is less than 0,
y hat equals 0.
Moreover, we saw that this leads to a decision boundary
of w transpose x equals 0.
So how does this compare with our new rule involving
thresholding conditional probabilities using the default
value of 0.5?
To see this, let's look at the plot of a logistic function.
And note that this function, applied at 0, equals 0.5.
So in other words, when w transpose x equals 0
and we apply it to the sigmoid function, we get back 0.5.
Hence, when using a threshold of 0.5,
the decision boundaries are identical.
