{
 "metadata": {
  "name": "",
  "signature": "sha256:8ee2e24675e7381e8f0dfbff6495ffef88ffbe156d105a13b963c116699fc372"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.io import imread\n",
      "from skimage.transform import resize\n",
      "from sklearn.ensemble import RandomForestClassifier as RF\n",
      "import glob\n",
      "import os\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "from sklearn.metrics import classification_report\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import colors\n",
      "from pylab import cm\n",
      "from skimage import segmentation\n",
      "from skimage.morphology import watershed\n",
      "from skimage import measure\n",
      "from skimage import morphology\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import ndimage\n",
      "from skimage.feature import peak_local_max\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "import cv2\n",
      "import cv2.cv as cv\n",
      "import random\n",
      "\n",
      "from scipy.cluster.vq import *\n",
      "from sklearn.preprocessing import StandardScaler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ~/git/datamining/Kaggle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/nhonaitran/git/datamining/Kaggle\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the classnames from the directory structure\n",
      "dirs = list(set(glob.glob(os.path.join(\"Data\",\"train\", \"*\"))).difference(set(glob.glob(os.path.join(\"Data\",\"train\",\"*.*\")))))\n",
      "dirs.sort()\n",
      "\n",
      "top_k = 9\n",
      "#directory_names = dirs[0:top_k]\n",
      "directory_names=dirs\n",
      "print directory_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Data\\\\train\\\\acantharia_protist', 'Data\\\\train\\\\acantharia_protist_big_center', 'Data\\\\train\\\\acantharia_protist_halo', 'Data\\\\train\\\\amphipods', 'Data\\\\train\\\\appendicularian_fritillaridae', 'Data\\\\train\\\\appendicularian_s_shape', 'Data\\\\train\\\\appendicularian_slight_curve', 'Data\\\\train\\\\appendicularian_straight', 'Data\\\\train\\\\artifacts', 'Data\\\\train\\\\artifacts_edge', 'Data\\\\train\\\\chaetognath_non_sagitta', 'Data\\\\train\\\\chaetognath_other', 'Data\\\\train\\\\chaetognath_sagitta', 'Data\\\\train\\\\chordate_type1', 'Data\\\\train\\\\copepod_calanoid', 'Data\\\\train\\\\copepod_calanoid_eggs', 'Data\\\\train\\\\copepod_calanoid_eucalanus', 'Data\\\\train\\\\copepod_calanoid_flatheads', 'Data\\\\train\\\\copepod_calanoid_frillyAntennae', 'Data\\\\train\\\\copepod_calanoid_large', 'Data\\\\train\\\\copepod_calanoid_large_side_antennatucked', 'Data\\\\train\\\\copepod_calanoid_octomoms', 'Data\\\\train\\\\copepod_calanoid_small_longantennae', 'Data\\\\train\\\\copepod_cyclopoid_copilia', 'Data\\\\train\\\\copepod_cyclopoid_oithona', 'Data\\\\train\\\\copepod_cyclopoid_oithona_eggs', 'Data\\\\train\\\\copepod_other', 'Data\\\\train\\\\crustacean_other', 'Data\\\\train\\\\ctenophore_cestid', 'Data\\\\train\\\\ctenophore_cydippid_no_tentacles', 'Data\\\\train\\\\ctenophore_cydippid_tentacles', 'Data\\\\train\\\\ctenophore_lobate', 'Data\\\\train\\\\unknown_blobs_and_smudges', 'Data\\\\train\\\\unknown_sticks', 'Data\\\\train\\\\unknown_unclassified']\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find the largest nonzero region\n",
      "def getLargestRegion(props, labelmap, imagethres):\n",
      "    regionmaxprop = None\n",
      "    for regionprop in props:\n",
      "        # check to see if the region is at least 50% nonzero\n",
      "        if sum(imagethres[labelmap == regionprop.label])*1.0/regionprop.area < 0.50:\n",
      "            continue\n",
      "        if regionmaxprop is None:\n",
      "            regionmaxprop = regionprop\n",
      "        if regionmaxprop.filled_area < regionprop.filled_area:\n",
      "            regionmaxprop = regionprop\n",
      "    return regionmaxprop\n",
      "\n",
      "def getGlobalFeatures(image):\n",
      "    image = image.copy()\n",
      "    \n",
      "    # thresholding the image on the the mean value\n",
      "    # to reduce noise in the image, eliminate some of the background\n",
      "    imagethr = np.where(image > np.mean(image),0.,1.0)\n",
      "\n",
      "    # dilate the image to connect neighboring pixels\n",
      "    imdilated = morphology.dilation(imagethr, np.ones((4,4)))\n",
      "\n",
      "    # alculate the labels for connected regions Create the label list\n",
      "    label_list = measure.label(imdilated)\n",
      "    label_list = imagethr*label_list\n",
      "    label_list = label_list.astype(int)\n",
      "    \n",
      "    region_list = measure.regionprops(label_list)\n",
      "    maxregion = getLargestRegion(region_list, label_list, imagethr)\n",
      "    \n",
      "    # guard against cases where the segmentation fails by providing zeros\n",
      "    filled_area = 0.0\n",
      "    perimeter = 0.0\n",
      "    ratio = 0.0\n",
      "    compactness = 0.0\n",
      "    moments=np.zeros([7,1])\n",
      "    if (not maxregion is None):\n",
      "        if ((maxregion.major_axis_length != 0.0)):\n",
      "            ratio = maxregion.minor_axis_length*1.0 / maxregion.major_axis_length\n",
      "        \n",
      "        no_of_pixels_in_region = maxregion.area\n",
      "        if (no_of_pixels_in_region == 0.0):\n",
      "            no_of_pixels_in_region = 0.0001  # do this to prevent divide-by-zero when calc compactness\n",
      "            \n",
      "        filled_area = maxregion.filled_area\n",
      "        perimeter = maxregion.perimeter\n",
      "        compactness = perimeter * perimeter / no_of_pixels_in_region\n",
      "        moments = maxregion.moments_hu\n",
      "    return(compactness, filled_area, perimeter, ratio, moments)\n",
      "    \n",
      "def getFeaturesUsingSIFT(k = 12):\n",
      "    des_list=[]\n",
      "    # Navigate through the list of directories\n",
      "    for folder in directory_names:\n",
      "        for fileNameDir in os.walk(folder):   \n",
      "            for fileName in fileNameDir[2]:\n",
      "                # Only read in the images\n",
      "                if fileName[-4:] != \".jpg\":\n",
      "                  continue\n",
      "\n",
      "                # Read in the images and create the features\n",
      "                nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "                image = imread(nameFileImage, as_grey=True)    \n",
      "\n",
      "                sift = cv2.SIFT()\n",
      "                kp, des = sift.detectAndCompute(image,None)\n",
      "                if (des==None):\n",
      "                    des=np.array([[0]*128])\n",
      "                des_list.append(des)\n",
      "    \n",
      "    \n",
      "    \n",
      "    # Using Bag of Words (Visual Words) model \n",
      "    # for having same size of features per image\n",
      "    \n",
      "    descriptors =[]\n",
      "    descriptors = np.vstack(des_list) \n",
      "\n",
      "    # Perform k-means clustering\n",
      "    #k = 12\n",
      "    voc, variance = kmeans(descriptors, k, 1) \n",
      "\n",
      "    # Calculate the histogram of features\n",
      "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
      "    for i in xrange(len(des_list)):\n",
      "        words, distance = vq(des_list[i],voc)\n",
      "        for w in words:\n",
      "            im_features[i][w] += 1\n",
      "\n",
      "    # Scaling the words\n",
      "    stdSlr = StandardScaler().fit(im_features)\n",
      "    im_features = stdSlr.transform(im_features)\n",
      "    # im_features has k columns with the number of image rows\n",
      "    # because we clustered all the descriptors (for all images) into k clusters\n",
      "    # and the feature for each image will be histogram of theses clusters\n",
      "    # meaning that each image has k features that each feature is the number of \n",
      "    # descriptors that are belonged to that cluster. \n",
      "\n",
      "    #return(features)\n",
      "    return(im_features)\n",
      "\n",
      "\n",
      "def getFeaturesUsingSURF(k = 12):\n",
      "    des_list=[]\n",
      "    # Navigate through the list of directories\n",
      "    for folder in directory_names:\n",
      "        for fileNameDir in os.walk(folder):   \n",
      "            for fileName in fileNameDir[2]:\n",
      "                # Only read in the images\n",
      "                if fileName[-4:] != \".jpg\":\n",
      "                  continue\n",
      "\n",
      "                # Read in the images and create the features\n",
      "                nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "                image = imread(nameFileImage, as_grey=True)    \n",
      "\n",
      "                surf = cv2.SURF(400)\n",
      "                kp, des = surf.detectAndCompute(image,None)\n",
      "                if (des==None):\n",
      "                    des=np.array([[0]*128])\n",
      "                des_list.append(des)\n",
      "    \n",
      "    \n",
      "    \n",
      "    # Using Bag of Words (Visual Words) model \n",
      "    # for having same size of features per image\n",
      "    \n",
      "    descriptors =[]\n",
      "    descriptors = np.vstack(des_list) \n",
      "\n",
      "    # Perform k-means clustering\n",
      "    #k = 12\n",
      "    voc, variance = kmeans(descriptors, k, 1) \n",
      "\n",
      "    # Calculate the histogram of features\n",
      "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
      "    for i in xrange(len(des_list)):\n",
      "        words, distance = vq(des_list[i],voc)\n",
      "        for w in words:\n",
      "            im_features[i][w] += 1\n",
      "\n",
      "    # Scaling the words\n",
      "    stdSlr = StandardScaler().fit(im_features)\n",
      "    im_features = stdSlr.transform(im_features)\n",
      "    # im_features has k columns with the number of image rows\n",
      "    # because we clustered all the descriptors (for all images) into k clusters\n",
      "    # and the feature for each image will be histogram of theses clusters\n",
      "    # meaning that each image has k features that each feature is the number of \n",
      "    # descriptors that are belonged to that cluster. \n",
      "\n",
      "    #return(features)\n",
      "    return(im_features)    \n",
      "\n",
      "\n",
      "\n",
      "def getFeaturesUsingORB(k = 12):\n",
      "    des_list=[]\n",
      "    # Navigate through the list of directories\n",
      "    for folder in directory_names:\n",
      "        for fileNameDir in os.walk(folder):   \n",
      "            for fileName in fileNameDir[2]:\n",
      "                # Only read in the images\n",
      "                if fileName[-4:] != \".jpg\":\n",
      "                  continue\n",
      "\n",
      "                # Read in the images and create the features\n",
      "                nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "                image = imread(nameFileImage, as_grey=True)    \n",
      "\n",
      "                orb = cv2.ORB()\n",
      "                kp, des = orb.detectAndCompute(image,None)\n",
      "                if (des==None):\n",
      "                    des=np.array([[0]*32])\n",
      "                des_list.append(des)\n",
      "    \n",
      "    \n",
      "    \n",
      "    # Using Bag of Words (Visual Words) model \n",
      "    # for having same size of features per image\n",
      "    \n",
      "    descriptors =[]\n",
      "    descriptors = np.vstack(des_list) \n",
      "\n",
      "    # Perform k-means clustering\n",
      "    #k = 12\n",
      "    voc, variance = kmeans(descriptors, k, 1) \n",
      "\n",
      "    # Calculate the histogram of features\n",
      "    im_features = np.zeros((len(des_list), k), \"float32\")\n",
      "    for i in xrange(len(des_list)):\n",
      "        words, distance = vq(des_list[i],voc)\n",
      "        for w in words:\n",
      "            im_features[i][w] += 1\n",
      "\n",
      "    # Scaling the words\n",
      "    stdSlr = StandardScaler().fit(im_features)\n",
      "    im_features = stdSlr.transform(im_features)\n",
      "    # im_features has k columns with the number of image rows\n",
      "    # because we clustered all the descriptors (for all images) into k clusters\n",
      "    # and the feature for each image will be histogram of theses clusters\n",
      "    # meaning that each image has k features that each feature is the number of \n",
      "    # descriptors that are belonged to that cluster. \n",
      "\n",
      "    #return(features)\n",
      "    return(im_features)\n",
      "\n",
      "#def getCircles(image, filename, param1=50,param2=30,minRadius=1,maxRadius=100, showimage=True):\n",
      "#    if (showimage):\n",
      "#        sub1 = plt.subplot(1,2,1)\n",
      "#        plt.imshow(image)\n",
      "#        sub1.set_title(fileName)\n",
      "\n",
      "#    gray = imread(fileImage, as_grey=True)    \n",
      "    \n",
      "#    kernel_size = 5\n",
      "#    # smooth image to reduce the number of false positives\n",
      "#    img_smooth = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
      "    \n",
      "#    circles = cv2.HoughCircles(gray,cv.CV_HOUGH_GRADIENT,1,20,param1,param2,minRadius,maxRadius)\n",
      "#    if (circles == None):\n",
      "#        no_of_circles = 0\n",
      "#    else:\n",
      "#        circles = np.uint16(np.around(circles))\n",
      "#        no_of_circles = len(circles)\n",
      "#        img = image.copy()\n",
      "#        if (showimage):\n",
      "#            for i in circles[0,:]:\n",
      "#                # draw the outer circle\n",
      "#                cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)\n",
      "#                # draw the center of the circle\n",
      "#                cv2.circle(img,(i[0],i[1]),2,(0,0,255),3)\n",
      "#               \n",
      "#     return(no_of_circles)\n",
      "                \n",
      "def getCornerFeatures(image, filename, maxCorners=25, qualityLevel=0.01, minDistance=10, showimage=True):\n",
      "    radius = 2\n",
      "    color = (0,0,0) #(255,255,255) #white color, (0,0,0)=black color\n",
      "    thickness = -1 #thickness of the circle outline, if positive. \n",
      "                  #negative thickness means that a filled circle is to be drawn.\n",
      "    if (showimage):\n",
      "        sub1 = plt.subplot(1,2,1)\n",
      "        plt.imshow(image)\n",
      "        sub1.set_title(fileName)\n",
      "\n",
      "    gray = imread(filename, as_grey=True)\n",
      "    corners = cv2.goodFeaturesToTrack(gray, maxCorners, qualityLevel, minDistance)\n",
      "    if (corners == None):\n",
      "        no_of_corners = 0\n",
      "        x_coord_std = 0.0\n",
      "        y_coord_std = 0.0\n",
      "    else:\n",
      "        corners = np.int0(corners)\n",
      "        no_of_corners = len(corners)\n",
      "        #print(corners) #contain x,y coordinate pairs of the corners\n",
      "        #print size(corners)\n",
      "        \n",
      "        x_coord_std = corners.std(axis=0)[0][0]\n",
      "        y_coord_std = corners.std(axis=0)[0][1]\n",
      "        \n",
      "        image2 = image.copy()\n",
      "        for corner in corners:\n",
      "            x,y = corner.ravel()\n",
      "            cv2.circle(image2, (x,y), radius, color, thickness)\n",
      "        \n",
      "        if(showimage):\n",
      "            sub2 = plt.subplot(1,2,2)\n",
      "            plt.imshow(image2)\n",
      "            sub2.set_title(\"...with corners added ({0} corners found)\".format(len(corners)))\n",
      "            plt.show()\n",
      "            \n",
      "    return(no_of_corners, x_coord_std, y_coord_std)\n",
      "                \n",
      "def computePerformance(X, y, namesClasses, cv_folds=10):\n",
      "    # parameters for SVM model selection\n",
      "    kernel = ['rbf']\n",
      "    gamma_range = 10.0 ** np.arange(-4, 2)\n",
      "    C_range = 10.0 ** np.arange(0, 4)\n",
      "    params_grid = dict(kernel=kernel, gamma=gamma_range, C=C_range)\n",
      "    #print params_grid\n",
      "\n",
      "    # find optimal hyperparameters\n",
      "    svm_models = GridSearchCV(SVC(), param_grid=params_grid, n_jobs=-1).fit(X, y)\n",
      "    #for params, mean_score, scores in svm_models_2.grid_scores_:\n",
      "    #    print(\"%10.3f for %r\" % (mean_score, params))\n",
      "    best_c = svm_models.best_params_['C']\n",
      "    best_gamma = svm_models.best_params_['gamma']\n",
      "    print svm_models.best_params_\n",
      "\n",
      "    # compute overall accuracy\n",
      "    fit = SVC(kernel='rbf', C=best_c, gamma=best_gamma)\n",
      "    scores_all = cross_validation.cross_val_score(fit, X, y, cv=cv_folds, n_jobs=-1);\n",
      "    print \"Accuracy of all classes\"\n",
      "    print np.mean(scores_all)\n",
      "    \n",
      "    # compute CV accuracy per class\n",
      "    kf = KFold(y, n_folds=cv_folds)\n",
      "    y_pred = y * 0\n",
      "    for train, test in kf:\n",
      "        X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
      "        model = SVC(kernel='rbf', C=best_c, gamma=best_gamma)\n",
      "        model.fit(X_train, y_train)\n",
      "        y_pred[test] = model.predict(X_test)\n",
      "    print classification_report(y, y_pred, target_names=namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rescale the images and create the combined metrics and training labels\n",
      "#get the total training images\n",
      "numberofImages = 0\n",
      "for folder in directory_names:\n",
      "    for fileNameDir in os.walk(folder):   \n",
      "        for fileName in fileNameDir[2]:\n",
      "             # Only read in the images\n",
      "            if fileName[-4:] != \".jpg\":\n",
      "              continue\n",
      "            numberofImages += 1\n",
      "\n",
      "# We'll rescale the images to be 25x25\n",
      "maxPixel = 25\n",
      "imageSize = maxPixel * maxPixel\n",
      "num_rows = numberofImages # one row for each image in the training dataset\n",
      "num_features = imageSize + 7 + 25 # for our ratio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# X is the feature vector with one row of features per image\n",
      "# consisting of the pixel values and our metric\n",
      "X = np.zeros((num_rows, num_features), dtype=float)\n",
      "# y is the numeric class label \n",
      "y = np.zeros((num_rows))\n",
      "\n",
      "\n",
      "\n",
      "files = []\n",
      "# Generate training data\n",
      "i = 0    \n",
      "label = 0\n",
      "# List of string of class names\n",
      "namesClasses = list()\n",
      "\n",
      "# SIFT features\n",
      "sift_features = getFeaturesUsingSIFT(k = 12)\n",
      "# SURF features\n",
      "surf_features = getFeaturesUsingSURF(k = 12)\n",
      "# ORB features\n",
      "orb_features = getFeaturesUsingORB(k = 12)\n",
      "\n",
      "\n",
      "\n",
      "print \"Reading images and compute features\"\n",
      "# Navigate through the list of directories\n",
      "for folder in directory_names:\n",
      "    #print folder\n",
      "    # Append the string class name for each class\n",
      "    currentClass = folder.split(os.pathsep)[-1]\n",
      "    namesClasses.append(currentClass)\n",
      "    for fileNameDir in os.walk(folder):   \n",
      "        for fileName in fileNameDir[2]:\n",
      "            # Only read in the images\n",
      "            if fileName[-4:] != \".jpg\":\n",
      "              continue\n",
      "            \n",
      "            # Read in the images and create the features\n",
      "            nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "            image = imread(nameFileImage, as_grey=True)\n",
      "            no_of_corners, corners_x_coord_std, corners_y_coord_std = getCornerFeatures(image, nameFileImage, showimage=False)\n",
      "            \n",
      "\n",
      "            files.append(nameFileImage)\n",
      "            image = resize(image, (maxPixel, maxPixel))\n",
      "            \n",
      "            # store the rescaled image pixels and the axis ratio\n",
      "            X[i, 0:imageSize] = np.reshape(image, (1, imageSize))\n",
      "            \n",
      "            # global features\n",
      "            compactness, area, perimeter, axisratio, moments = getGlobalFeatures(image)\n",
      "            X[i, imageSize] = compactness\n",
      "            X[i, imageSize+1] = area #filled area\n",
      "            X[i, imageSize+2] = perimeter\n",
      "            X[i, imageSize+3] = axisratio\n",
      "            \n",
      "            # corner features\n",
      "            X[i, imageSize+4] = no_of_corners\n",
      "            X[i, imageSize+5] = corners_x_coord_std\n",
      "            X[i, imageSize+6] = corners_y_coord_std            \n",
      "            X[i, imageSize+7] = moments[0]\n",
      "            X[i, imageSize+8] = moments[1]\n",
      "            X[i, imageSize+9] = moments[2]\n",
      "            X[i, imageSize+10] = moments[3]\n",
      "            X[i, imageSize+11] = moments[4]\n",
      "            X[i, imageSize+12] = moments[5]\n",
      "            X[i, imageSize+13] = moments[6]\n",
      "            # adding SIFT features         \n",
      "            X[i, imageSize+13:imageSize+25] = sift_features[i,]\n",
      "            \n",
      "            # adding SURF features    \n",
      "            #X[i, imageSize+25:imageSize+37] = surf_features[i,]\n",
      "            \n",
      "            # adding ORB features      \n",
      "            #X[i, imageSize+37:imageSize+49] = orb_features[i,]\n",
      "            \n",
      "            # Store the classlabel\n",
      "            y[i] = label\n",
      "            i += 1\n",
      "            # report progress for each 5% done  \n",
      "            report = [int((j+1)*num_rows/20.) for j in range(20)]\n",
      "            if i in report: print np.ceil(i *100.0 / num_rows), \"% done\"\n",
      "    label += 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading images and compute features\n",
        "5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "10.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "15.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "20.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "25.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "30.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "35.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "40.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "45.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "50.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "55.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "60.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "65.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "70.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "75.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "80.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "85.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "90.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "95.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "100.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification performance using raw pixel of image as features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 632) (3071,)\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[5:,0:imageSize]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
        " [ 1.          1.          1.         ...,  1.          1.          1.        ]\n",
        " [ 1.          1.          1.         ...,  0.99990588  1.          1.        ]\n",
        " ..., \n",
        " [ 0.99691294  0.99898353  0.99628235 ...,  0.91987451  0.93888627\n",
        "   0.95715765]\n",
        " [ 1.          0.99887059  0.99952941 ...,  1.          0.98123922\n",
        "   0.93032157]\n",
        " [ 0.99351529  0.98484706  0.9377098  ...,  0.888       0.75230745\n",
        "   0.14870275]]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,0:imageSize], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.10000000000000001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.778162308715\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.91      0.96      0.93       889\n",
        "data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      data/train/acantharia_protist_halo       0.72      0.46      0.56        71\n",
        "                    data/train/amphipods       0.97      0.61      0.75        49\n",
        "data/train/appendicularian_fritillaridae       0.25      0.06      0.10        16\n",
        "      data/train/appendicularian_s_shape       0.73      0.76      0.74       696\n",
        " data/train/appendicularian_slight_curve       0.61      0.62      0.61       532\n",
        "     data/train/appendicularian_straight       0.60      0.49      0.54       242\n",
        "                    data/train/artifacts       0.88      0.90      0.89       393\n",
        "               data/train/artifacts_edge       0.77      0.84      0.80       170\n",
        "\n",
        "                             avg / total       0.77      0.78      0.77      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/nhonaitran/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using global features: compactness, filled area, perimeter, axis ratio"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize:imageSize+4].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 4)\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[5:,imageSize:imageSize+4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  28.59321728   61.           41.76345597    0.62007183]\n",
        " [  42.443471     59.           50.04163056    0.68971977]\n",
        " [  38.13678878   56.           46.21320344    0.78875574]\n",
        " ..., \n",
        " [ 108.69469446  179.          138.70458146    0.79669201]\n",
        " [ 124.62222215  207.          160.22539674    0.8740351 ]\n",
        " [   0.            0.            0.            0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize:imageSize+4], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.606285467296\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.84      0.86      0.85       889\n",
        "data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      data/train/acantharia_protist_halo       0.14      0.01      0.03        71\n",
        "                    data/train/amphipods       0.63      0.55      0.59        49\n",
        "data/train/appendicularian_fritillaridae       1.00      0.06      0.12        16\n",
        "      data/train/appendicularian_s_shape       0.45      0.70      0.55       696\n",
        " data/train/appendicularian_slight_curve       0.33      0.25      0.28       532\n",
        "     data/train/appendicularian_straight       0.47      0.06      0.11       242\n",
        "                    data/train/artifacts       0.73      0.70      0.72       393\n",
        "               data/train/artifacts_edge       0.79      0.89      0.83       170\n",
        "\n",
        "                             avg / total       0.59      0.61      0.58      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features (corners)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+4:imageSize+7].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 3)\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+4:imageSize+7])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  5.           8.61162006   0.        ]\n",
        " [ 11.          18.42160069   0.        ]\n",
        " [  6.          12.61502631   0.        ]\n",
        " ..., \n",
        " [ 11.           8.84485189   0.        ]\n",
        " [ 11.           9.65178868   0.        ]\n",
        " [ 10.          10.49571341   0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+4:imageSize+7], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 100.0, 'gamma': 0.01}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.520486394357\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.61      0.59      0.60       889\n",
        "data/train/acantharia_protist_big_center       0.50      0.23      0.32        13\n",
        "      data/train/acantharia_protist_halo       0.46      0.37      0.41        71\n",
        "                    data/train/amphipods       0.00      0.00      0.00        49\n",
        "data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      data/train/appendicularian_s_shape       0.41      0.71      0.52       696\n",
        " data/train/appendicularian_slight_curve       0.36      0.18      0.24       532\n",
        "     data/train/appendicularian_straight       0.54      0.10      0.17       242\n",
        "                    data/train/artifacts       0.63      0.75      0.68       393\n",
        "               data/train/artifacts_edge       0.81      0.76      0.78       170\n",
        "\n",
        "                             avg / total       0.51      0.52      0.49      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features : SIFT"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+7:imageSize+19].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 12)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+7:imageSize+19])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.57589501 -0.52179176  0.49314028 ..., -0.6706782  -0.52181679\n",
        "  -0.4758555 ]\n",
        " [ 0.78874511 -0.52179176 -0.32902789 ..., -0.6706782  -0.52181679\n",
        "  -0.4758555 ]\n",
        " [-0.57589501 -0.52179176 -0.32902789 ..., -0.6706782   0.92513531\n",
        "  -0.4758555 ]\n",
        " ..., \n",
        " [-0.57589501 -0.52179176 -0.32902789 ..., -0.6706782  -0.52181679\n",
        "   2.10148549]\n",
        " [-0.57589501 -0.52179176 -0.32902789 ..., -0.6706782   0.20165925\n",
        "   2.10148549]\n",
        " [-0.57589501 -0.52179176 -0.32902789 ..., -0.6706782  -0.52181679\n",
        "  -0.4758555 ]]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+7:imageSize+19], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "Accuracy of all classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.659740853359\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data\\train\\acantharia_protist       0.73      0.95      0.82       889\n",
        "Data\\train\\acantharia_protist_big_center       0.25      0.08      0.12        13\n",
        "      Data\\train\\acantharia_protist_halo       0.85      0.15      0.26        71\n",
        "                    Data\\train\\amphipods       0.48      0.24      0.32        49\n",
        "Data\\train\\appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data\\train\\appendicularian_s_shape       0.66      0.74      0.70       696\n",
        " Data\\train\\appendicularian_slight_curve       0.42      0.46      0.44       532\n",
        "     Data\\train\\appendicularian_straight       0.60      0.21      0.31       242\n",
        "                    Data\\train\\artifacts       0.78      0.61      0.69       393\n",
        "               Data\\train\\artifacts_edge       0.94      0.64      0.76       170\n",
        "\n",
        "                             avg / total       0.66      0.66      0.64      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\metrics\\metrics.py:1771: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features : SURF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+19:imageSize+31].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 12)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+19:imageSize+31])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.40828651  0.69930905 -0.20106815 ...,  0.          0.          0.38905981]\n",
        " [-0.40828651  2.37579465 -0.20106815 ...,  0.          0.         -2.38955092]\n",
        " [-0.40828651  0.69930905 -0.20106815 ...,  0.          0.         -2.38955092]\n",
        " ..., \n",
        " [-0.40828651 -0.97717661 -0.20106815 ...,  0.          0.          0.38905981]\n",
        " [-0.40828651 -0.97717661 -0.20106815 ...,  0.          0.          0.38905981]\n",
        " [-0.40828651 -0.97717661  0.43094853 ...,  0.          0.          0.38905981]]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+19:imageSize+31], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.01}\n",
        "Accuracy of all classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.58742016406\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data\\train\\acantharia_protist       0.76      0.69      0.73       889\n",
        "Data\\train\\acantharia_protist_big_center       0.75      0.23      0.35        13\n",
        "      Data\\train\\acantharia_protist_halo       0.60      0.08      0.15        71\n",
        "                    Data\\train\\amphipods       0.54      0.41      0.47        49\n",
        "Data\\train\\appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data\\train\\appendicularian_s_shape       0.57      0.74      0.64       696\n",
        " Data\\train\\appendicularian_slight_curve       0.50      0.46      0.48       532\n",
        "     Data\\train\\appendicularian_straight       0.66      0.13      0.21       242\n",
        "                    Data\\train\\artifacts       0.43      0.77      0.55       393\n",
        "               Data\\train\\artifacts_edge       0.92      0.39      0.55       170\n",
        "\n",
        "                             avg / total       0.62      0.59      0.57      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using local features : ORB"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize+31:imageSize+43].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 12)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(X[:,imageSize+31:imageSize+43])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.09007179 -0.16093856 -0.24020512 ..., -0.14756323 -0.0740727   0.        ]\n",
        " [-0.09007179 -0.16093856  2.96148753 ...,  1.07555866 -0.0740727   0.        ]\n",
        " [-0.09007179 -0.16093856  1.68081045 ..., -0.14756323 -0.0740727   0.        ]\n",
        " ..., \n",
        " [-0.09007179 -0.16093856 -0.24020512 ..., -0.14756323 -0.0740727   0.        ]\n",
        " [-0.09007179 -0.16093856 -0.24020512 ..., -0.14756323 -0.0740727   0.        ]\n",
        " [-0.09007179 -0.16093856 -0.24020512 ..., -0.14756323 -0.0740727   0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize+31:imageSize+43], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.01}\n",
        "Accuracy of all classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.339964345176\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           Data\\train\\acantharia_protist       0.93      0.39      0.55       889\n",
        "Data\\train\\acantharia_protist_big_center       0.50      0.46      0.48        13\n",
        "      Data\\train\\acantharia_protist_halo       0.00      0.00      0.00        71\n",
        "                    Data\\train\\amphipods       0.14      0.02      0.04        49\n",
        "Data\\train\\appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      Data\\train\\appendicularian_s_shape       0.26      0.98      0.41       696\n",
        " Data\\train\\appendicularian_slight_curve       0.23      0.01      0.01       532\n",
        "     Data\\train\\appendicularian_straight       0.56      0.04      0.08       242\n",
        "                    Data\\train\\artifacts       0.00      0.00      0.00       393\n",
        "               Data\\train\\artifacts_edge       0.00      0.00      0.00       170\n",
        "\n",
        "                             avg / total       0.42      0.34      0.26      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "C+G+M+sift"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize:imageSize+25], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "Accuracy of all classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.563018664293\n",
        "                                                      precision    recall  f1-score   support\n",
        "\n",
        "                       Data\\train\\acantharia_protist       0.76      0.85      0.80       889\n",
        "            Data\\train\\acantharia_protist_big_center       0.60      0.46      0.52        13\n",
        "                  Data\\train\\acantharia_protist_halo       0.68      0.61      0.64        71\n",
        "                                Data\\train\\amphipods       0.12      0.06      0.08        49\n",
        "            Data\\train\\appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "                  Data\\train\\appendicularian_s_shape       0.49      0.66      0.56       696\n",
        "             Data\\train\\appendicularian_slight_curve       0.33      0.33      0.33       532\n",
        "                 Data\\train\\appendicularian_straight       0.38      0.09      0.14       242\n",
        "                                Data\\train\\artifacts       0.86      0.88      0.87       393\n",
        "                           Data\\train\\artifacts_edge       0.95      0.95      0.95       170\n",
        "                  Data\\train\\chaetognath_non_sagitta       0.66      0.69      0.67       815\n",
        "                        Data\\train\\chaetognath_other       0.62      0.80      0.70      1934\n",
        "                      Data\\train\\chaetognath_sagitta       0.59      0.24      0.34       694\n",
        "                           Data\\train\\chordate_type1       0.67      0.65      0.66        77\n",
        "                         Data\\train\\copepod_calanoid       0.40      0.29      0.34       681\n",
        "                    Data\\train\\copepod_calanoid_eggs       0.41      0.25      0.31       173\n",
        "               Data\\train\\copepod_calanoid_eucalanus       0.60      0.46      0.52        96\n",
        "               Data\\train\\copepod_calanoid_flatheads       0.00      0.00      0.00       178\n",
        "          Data\\train\\copepod_calanoid_frillyAntennae       0.57      0.06      0.11        63\n",
        "                   Data\\train\\copepod_calanoid_large       0.49      0.58      0.53       286\n",
        "Data\\train\\copepod_calanoid_large_side_antennatucked       0.27      0.24      0.25       106\n",
        "                Data\\train\\copepod_calanoid_octomoms       0.25      0.02      0.04        49\n",
        "      Data\\train\\copepod_calanoid_small_longantennae       0.60      0.56      0.58        87\n",
        "                Data\\train\\copepod_cyclopoid_copilia       0.67      0.47      0.55        30\n",
        "                Data\\train\\copepod_cyclopoid_oithona       0.45      0.56      0.50       899\n",
        "           Data\\train\\copepod_cyclopoid_oithona_eggs       0.54      0.71      0.61      1189\n",
        "                            Data\\train\\copepod_other       0.00      0.00      0.00        24\n",
        "                         Data\\train\\crustacean_other       0.34      0.26      0.30       201\n",
        "                        Data\\train\\ctenophore_cestid       0.85      0.69      0.76       113\n",
        "         Data\\train\\ctenophore_cydippid_no_tentacles       0.21      0.07      0.11        42\n",
        "            Data\\train\\ctenophore_cydippid_tentacles       0.55      0.21      0.30        53\n",
        "                        Data\\train\\ctenophore_lobate       0.78      0.74      0.76        38\n",
        "                Data\\train\\unknown_blobs_and_smudges       0.39      0.45      0.42       317\n",
        "                           Data\\train\\unknown_sticks       0.46      0.11      0.18       175\n",
        "                     Data\\train\\unknown_unclassified       0.42      0.30      0.35       425\n",
        "\n",
        "                                         avg / total       0.54      0.56      0.54     11816\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\sklearn\\metrics\\metrics.py:1771: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "PCA on Raw pixels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA as sklearnPCA\n",
      "sklearn_pca = sklearnPCA(50)\n",
      "X_wPCA = sklearn_pca.fit_transform(X[:,0:imageSize])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_wPCA.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "50\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "PCA on Raw+C+G+M+sift"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_new=np.zeros([X.shape[0],X_wPCA.shape[1]+26])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_new.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11816, 76)\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_new[:,0:50]=X_wPCA\n",
      "X_new[:,51:]=X[:,imageSize:imageSize+25]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_new.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11816, 76)\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X_new, y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "Accuracy of all classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.649425884055\n",
        "                                                      precision    recall  f1-score   support\n",
        "\n",
        "                       Data\\train\\acantharia_protist       0.84      0.91      0.87       889\n",
        "            Data\\train\\acantharia_protist_big_center       0.43      0.46      0.44        13\n",
        "                  Data\\train\\acantharia_protist_halo       0.76      0.68      0.72        71\n",
        "                                Data\\train\\amphipods       0.23      0.20      0.22        49\n",
        "            Data\\train\\appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "                  Data\\train\\appendicularian_s_shape       0.60      0.73      0.66       696\n",
        "             Data\\train\\appendicularian_slight_curve       0.52      0.56      0.54       532\n",
        "                 Data\\train\\appendicularian_straight       0.44      0.29      0.35       242\n",
        "                                Data\\train\\artifacts       0.88      0.93      0.90       393\n",
        "                           Data\\train\\artifacts_edge       0.94      0.94      0.94       170\n",
        "                  Data\\train\\chaetognath_non_sagitta       0.68      0.68      0.68       815\n",
        "                        Data\\train\\chaetognath_other       0.66      0.80      0.72      1934\n",
        "                      Data\\train\\chaetognath_sagitta       0.59      0.30      0.40       694\n",
        "                           Data\\train\\chordate_type1       0.73      0.73      0.73        77\n",
        "                         Data\\train\\copepod_calanoid       0.50      0.63      0.55       681\n",
        "                    Data\\train\\copepod_calanoid_eggs       0.60      0.45      0.52       173\n",
        "               Data\\train\\copepod_calanoid_eucalanus       0.65      0.51      0.57        96\n",
        "               Data\\train\\copepod_calanoid_flatheads       0.20      0.01      0.01       178\n",
        "          Data\\train\\copepod_calanoid_frillyAntennae       0.43      0.10      0.16        63\n",
        "                   Data\\train\\copepod_calanoid_large       0.61      0.65      0.63       286\n",
        "Data\\train\\copepod_calanoid_large_side_antennatucked       0.50      0.46      0.48       106\n",
        "                Data\\train\\copepod_calanoid_octomoms       0.45      0.10      0.17        49\n",
        "      Data\\train\\copepod_calanoid_small_longantennae       0.71      0.69      0.70        87\n",
        "                Data\\train\\copepod_cyclopoid_copilia       0.53      0.53      0.53        30\n",
        "                Data\\train\\copepod_cyclopoid_oithona       0.67      0.74      0.70       899\n",
        "           Data\\train\\copepod_cyclopoid_oithona_eggs       0.74      0.77      0.76      1189\n",
        "                            Data\\train\\copepod_other       0.00      0.00      0.00        24\n",
        "                         Data\\train\\crustacean_other       0.41      0.37      0.39       201\n",
        "                        Data\\train\\ctenophore_cestid       0.83      0.76      0.79       113\n",
        "         Data\\train\\ctenophore_cydippid_no_tentacles       0.45      0.36      0.40        42\n",
        "            Data\\train\\ctenophore_cydippid_tentacles       0.52      0.30      0.38        53\n",
        "                        Data\\train\\ctenophore_lobate       0.82      0.71      0.76        38\n",
        "                Data\\train\\unknown_blobs_and_smudges       0.47      0.46      0.46       317\n",
        "                           Data\\train\\unknown_sticks       0.60      0.38      0.46       175\n",
        "                     Data\\train\\unknown_unclassified       0.43      0.33      0.37       425\n",
        "\n",
        "                                         avg / total       0.63      0.65      0.63     11816\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using raw pixel, local features (corner,point-based), and global feaures."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X, y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 0.0001}\n",
        "Accuracy of all classes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.650029303396\n",
        "                                                      precision    recall  f1-score   support\n",
        "\n",
        "                       Data\\train\\acantharia_protist       0.84      0.91      0.87       889\n",
        "            Data\\train\\acantharia_protist_big_center       0.43      0.46      0.44        13\n",
        "                  Data\\train\\acantharia_protist_halo       0.76      0.70      0.73        71\n",
        "                                Data\\train\\amphipods       0.30      0.22      0.26        49\n",
        "            Data\\train\\appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "                  Data\\train\\appendicularian_s_shape       0.59      0.72      0.65       696\n",
        "             Data\\train\\appendicularian_slight_curve       0.51      0.54      0.52       532\n",
        "                 Data\\train\\appendicularian_straight       0.43      0.29      0.35       242\n",
        "                                Data\\train\\artifacts       0.89      0.92      0.90       393\n",
        "                           Data\\train\\artifacts_edge       0.93      0.95      0.94       170\n",
        "                  Data\\train\\chaetognath_non_sagitta       0.67      0.67      0.67       815\n",
        "                        Data\\train\\chaetognath_other       0.67      0.79      0.73      1934\n",
        "                      Data\\train\\chaetognath_sagitta       0.57      0.36      0.44       694\n",
        "                           Data\\train\\chordate_type1       0.77      0.77      0.77        77\n",
        "                         Data\\train\\copepod_calanoid       0.50      0.63      0.55       681\n",
        "                    Data\\train\\copepod_calanoid_eggs       0.57      0.46      0.51       173\n",
        "               Data\\train\\copepod_calanoid_eucalanus       0.65      0.53      0.59        96\n",
        "               Data\\train\\copepod_calanoid_flatheads       0.00      0.00      0.00       178\n",
        "          Data\\train\\copepod_calanoid_frillyAntennae       0.56      0.14      0.23        63\n",
        "                   Data\\train\\copepod_calanoid_large       0.59      0.62      0.60       286\n",
        "Data\\train\\copepod_calanoid_large_side_antennatucked       0.50      0.42      0.46       106\n",
        "                Data\\train\\copepod_calanoid_octomoms       0.64      0.14      0.23        49\n",
        "      Data\\train\\copepod_calanoid_small_longantennae       0.70      0.66      0.67        87\n",
        "                Data\\train\\copepod_cyclopoid_copilia       0.55      0.53      0.54        30\n",
        "                Data\\train\\copepod_cyclopoid_oithona       0.68      0.74      0.71       899\n",
        "           Data\\train\\copepod_cyclopoid_oithona_eggs       0.75      0.78      0.76      1189\n",
        "                            Data\\train\\copepod_other       0.00      0.00      0.00        24\n",
        "                         Data\\train\\crustacean_other       0.42      0.41      0.42       201\n",
        "                        Data\\train\\ctenophore_cestid       0.79      0.73      0.76       113\n",
        "         Data\\train\\ctenophore_cydippid_no_tentacles       0.41      0.36      0.38        42\n",
        "            Data\\train\\ctenophore_cydippid_tentacles       0.49      0.32      0.39        53\n",
        "                        Data\\train\\ctenophore_lobate       0.83      0.76      0.79        38\n",
        "                Data\\train\\unknown_blobs_and_smudges       0.47      0.47      0.47       317\n",
        "                           Data\\train\\unknown_sticks       0.59      0.38      0.46       175\n",
        "                     Data\\train\\unknown_unclassified       0.44      0.32      0.37       425\n",
        "\n",
        "                                         avg / total       0.63      0.65      0.64     11816\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 75
    }
   ],
   "metadata": {}
  }
 ]
}