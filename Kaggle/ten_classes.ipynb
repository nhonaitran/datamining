{
 "metadata": {
  "name": "",
  "signature": "sha256:329dc73b9a5284533871001c2c82cc822027cc6001c1439bd72d0d6174bea143"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.io import imread\n",
      "from skimage.transform import resize\n",
      "from sklearn.ensemble import RandomForestClassifier as RF\n",
      "import glob\n",
      "import os\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "from sklearn.metrics import classification_report\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import colors\n",
      "from pylab import cm\n",
      "from skimage import segmentation\n",
      "from skimage.morphology import watershed\n",
      "from skimage import measure\n",
      "from skimage import morphology\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy import ndimage\n",
      "from skimage.feature import peak_local_max\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "import cv2\n",
      "import cv2.cv as cv\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ~/git/datamining/Kaggle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/nhonaitran/git/datamining/Kaggle\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find the largest nonzero region\n",
      "def getLargestRegion(props, labelmap, imagethres):\n",
      "    regionmaxprop = None\n",
      "    for regionprop in props:\n",
      "        # check to see if the region is at least 50% nonzero\n",
      "        if sum(imagethres[labelmap == regionprop.label])*1.0/regionprop.area < 0.50:\n",
      "            continue\n",
      "        if regionmaxprop is None:\n",
      "            regionmaxprop = regionprop\n",
      "        if regionmaxprop.filled_area < regionprop.filled_area:\n",
      "            regionmaxprop = regionprop\n",
      "    return regionmaxprop\n",
      "\n",
      "def getMinorMajorRatio(image):\n",
      "    image = image.copy()\n",
      "    # Create the thresholded image to eliminate some of the background\n",
      "    imagethr = np.where(image > np.mean(image),0.,1.0)\n",
      "\n",
      "    #Dilate the image\n",
      "    imdilated = morphology.dilation(imagethr, np.ones((4,4)))\n",
      "\n",
      "    # Create the label list\n",
      "    label_list = measure.label(imdilated)\n",
      "    label_list = imagethr*label_list\n",
      "    label_list = label_list.astype(int)\n",
      "    \n",
      "    region_list = measure.regionprops(label_list)\n",
      "    maxregion = getLargestRegion(region_list, label_list, imagethr)\n",
      "    \n",
      "    # guard against cases where the segmentation fails by providing zeros\n",
      "    ratio = 0.0\n",
      "    if ((not maxregion is None) and (maxregion.major_axis_length != 0.0)):\n",
      "        ratio = 0.0 if maxregion is None else maxregion.minor_axis_length*1.0 / maxregion.major_axis_length\n",
      "    return ratio\n",
      "    \n",
      "def getFeaturesUsingORB(image, noOfFeatures = 5, noOfDescriptors = 25):\n",
      "    orb = cv2.ORB(nfeatures = noOfFeatures)\n",
      "    keypoints, descriptors = orb.detectAndCompute(image, mask=None)\n",
      "    features = []\n",
      "    if (descriptors != None and len(keypoints) >= noOfFeatures):\n",
      "        #print \"keypoints: \", len(keypoints), \"; no features found\"\n",
      "    #else:\n",
      "        rows = descriptors.shape[0]\n",
      "        cols = descriptors.shape[1]\n",
      "        #print rows, cols\n",
      "        \n",
      "        # choose random 5 keypoints and 25 descriptor\n",
      "        kp_index = [0,1,2,3,4]\n",
      "        if (rows > noOfFeatures):\n",
      "            kp_index = random.sample(rows, noOfFeatures)\n",
      "        #print kp_index\n",
      "        \n",
      "        resized_descriptors = descriptors[kp_index, 0:cols]\n",
      "        features = resized_descriptors.reshape(noOfFeatures*cols).astype(np.float32)\n",
      "        \n",
      "    #return(features)\n",
      "    return(keypoints, descriptors, features)\n",
      "\n",
      "#def getCircles(image, filename, param1=50,param2=30,minRadius=1,maxRadius=100, showimage=True):\n",
      "#    if (showimage):\n",
      "#        sub1 = plt.subplot(1,2,1)\n",
      "#        plt.imshow(image)\n",
      "#        sub1.set_title(fileName)\n",
      "\n",
      "#    gray = imread(fileImage, as_grey=True)    \n",
      "    \n",
      "#    kernel_size = 5\n",
      "#    # smooth image to reduce the number of false positives\n",
      "#    img_smooth = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
      "    \n",
      "#    circles = cv2.HoughCircles(gray,cv.CV_HOUGH_GRADIENT,1,20,param1,param2,minRadius,maxRadius)\n",
      "#    if (circles == None):\n",
      "#        no_of_circles = 0\n",
      "#    else:\n",
      "#        circles = np.uint16(np.around(circles))\n",
      "#        no_of_circles = len(circles)\n",
      "#        img = image.copy()\n",
      "#        if (showimage):\n",
      "#            for i in circles[0,:]:\n",
      "#                # draw the outer circle\n",
      "#                cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)\n",
      "#                # draw the center of the circle\n",
      "#                cv2.circle(img,(i[0],i[1]),2,(0,0,255),3)\n",
      "#               \n",
      "#     return(no_of_circles)\n",
      "                \n",
      "def getCornerFeatures(image, filename, maxCorners=25, qualityLevel=0.01, minDistance=10, showimage=True):\n",
      "    radius = 2\n",
      "    color = (0,0,0) #(255,255,255) #white color, (0,0,0)=black color\n",
      "    thickness = -1 #thickness of the circle outline, if positive. \n",
      "                  #negative thickness means that a filled circle is to be drawn.\n",
      "    if (showimage):\n",
      "        sub1 = plt.subplot(1,2,1)\n",
      "        plt.imshow(image)\n",
      "        sub1.set_title(fileName)\n",
      "\n",
      "    gray = imread(filename, as_grey=True)\n",
      "    corners = cv2.goodFeaturesToTrack(gray, maxCorners, qualityLevel, minDistance)\n",
      "    if (corners == None):\n",
      "        no_of_corners = 0\n",
      "        x_coord_std = 0.0\n",
      "        y_coord_std = 0.0\n",
      "    else:\n",
      "        corners = np.int0(corners)\n",
      "        no_of_corners = len(corners)\n",
      "        #print(corners) #contain x,y coordinate pairs of the corners\n",
      "        #print size(corners)\n",
      "        \n",
      "        x_coord_std = corners.std(axis=0)[0][0]\n",
      "        y_coord_std = corners.std(axis=1)[0][1]\n",
      "        #print (corners.std(axis=0)[0][0], corners.std(axis=0)[0][1])\n",
      "        image2 = image.copy()\n",
      "        for corner in corners:\n",
      "            x,y = corner.ravel()\n",
      "            cv2.circle(image2, (x,y), radius, color, thickness)\n",
      "        \n",
      "        if(showimage):\n",
      "            sub2 = plt.subplot(1,2,2)\n",
      "            plt.imshow(image2)\n",
      "            sub2.set_title(\"...with corners added ({0} corners found)\".format(len(corners)))\n",
      "            plt.show()\n",
      "            \n",
      "    return(no_of_corners, x_coord_std, y_coord_std)\n",
      "                \n",
      "def computePerformance(X, y, namesClasses, cv_folds=10):\n",
      "    # parameters for SVM model selection\n",
      "    kernel = ['rbf']\n",
      "    gamma_range = 10.0 ** np.arange(-4, 2)\n",
      "    C_range = 10.0 ** np.arange(0, 4)\n",
      "    params_grid = dict(kernel=kernel, gamma=gamma_range, C=C_range)\n",
      "    #print params_grid\n",
      "\n",
      "    # find optimal hyperparameters\n",
      "    svm_models = GridSearchCV(SVC(), param_grid=params_grid, n_jobs=-1).fit(X, y)\n",
      "    #for params, mean_score, scores in svm_models_2.grid_scores_:\n",
      "    #    print(\"%10.3f for %r\" % (mean_score, params))\n",
      "    best_c = svm_models.best_params_['C']\n",
      "    best_gamma = svm_models.best_params_['gamma']\n",
      "    print svm_models.best_params_\n",
      "\n",
      "    # compute overall accuracy\n",
      "    fit = SVC(kernel='rbf', C=best_c, gamma=best_gamma)\n",
      "    scores_all = cross_validation.cross_val_score(fit, X, y, cv=cv_folds, n_jobs=-1);\n",
      "    print \"Accuracy of all classes\"\n",
      "    print np.mean(scores_all)\n",
      "    \n",
      "    # compute CV accuracy per class\n",
      "    kf = KFold(y, n_folds=cv_folds)\n",
      "    y_pred = y * 0\n",
      "    for train, test in kf:\n",
      "        X_train, X_test, y_train, y_test = X[train,:], X[test,:], y[train], y[test]\n",
      "        model = SVC(kernel='rbf', C=best_c, gamma=best_gamma)\n",
      "        model.fit(X_train, y_train)\n",
      "        y_pred[test] = model.predict(X_test)\n",
      "    print classification_report(y, y_pred, target_names=namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the classnames from the directory structure\n",
      "dirs = list(set(glob.glob(os.path.join(\"data\",\"train\", \"*\"))).difference(set(glob.glob(os.path.join(\"data\",\"train\",\"*.*\")))))\n",
      "dirs.sort()\n",
      "\n",
      "top_k = 10\n",
      "directory_names = dirs[0:top_k]\n",
      "print directory_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['data/train/acantharia_protist', 'data/train/acantharia_protist_big_center', 'data/train/acantharia_protist_halo', 'data/train/amphipods', 'data/train/appendicularian_fritillaridae', 'data/train/appendicularian_s_shape', 'data/train/appendicularian_slight_curve', 'data/train/appendicularian_straight', 'data/train/artifacts', 'data/train/artifacts_edge']\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rescale the images and create the combined metrics and training labels\n",
      "#get the total training images\n",
      "numberofImages = 0\n",
      "for folder in directory_names:\n",
      "    for fileNameDir in os.walk(folder):   \n",
      "        for fileName in fileNameDir[2]:\n",
      "             # Only read in the images\n",
      "            if fileName[-4:] != \".jpg\":\n",
      "              continue\n",
      "            numberofImages += 1\n",
      "\n",
      "# We'll rescale the images to be 25x25\n",
      "maxPixel = 25\n",
      "imageSize = maxPixel * maxPixel\n",
      "num_rows = numberofImages # one row for each image in the training dataset\n",
      "num_features = imageSize + 4 # for our ratio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# X is the feature vector with one row of features per image\n",
      "# consisting of the pixel values and our metric\n",
      "X = np.zeros((num_rows, num_features), dtype=float)\n",
      "# y is the numeric class label \n",
      "y = np.zeros((num_rows))\n",
      "\n",
      "# feature: extracted using ORB\n",
      "noOfKeypoints = 5\n",
      "noOfDescriptors = 32\n",
      "num_features_orb = noOfKeypoints * noOfDescriptors\n",
      "X_orb = [] #np.zeros((num_rows, num_features_orb), dtype=float)\n",
      "Y_orb = []\n",
      "\n",
      "files = []\n",
      "# Generate training data\n",
      "i = 0    \n",
      "label = 0\n",
      "# List of string of class names\n",
      "namesClasses = list()\n",
      "\n",
      "print \"Reading images and compute features\"\n",
      "# Navigate through the list of directories\n",
      "for folder in directory_names:\n",
      "    #print folder\n",
      "    # Append the string class name for each class\n",
      "    currentClass = folder.split(os.pathsep)[-1]\n",
      "    namesClasses.append(currentClass)\n",
      "    for fileNameDir in os.walk(folder):   \n",
      "        for fileName in fileNameDir[2]:\n",
      "            # Only read in the images\n",
      "            if fileName[-4:] != \".jpg\":\n",
      "              continue\n",
      "            \n",
      "            # Read in the images and create the features\n",
      "            nameFileImage = \"{0}{1}{2}\".format(fileNameDir[0], os.sep, fileName)            \n",
      "            image = imread(nameFileImage, as_grey=True)\n",
      "            no_of_corners, corners_x_coord_std, corners_y_coord_std = getCornerFeatures(image, nameFileImage, showimage=False)\n",
      "\n",
      "            #store keypoints and descriptor values\n",
      "            kp, desc, features = getFeaturesUsingORB(image)\n",
      "            dimensions = len(features)\n",
      "            if dimensions > 0:\n",
      "                #X_orb[i, 0:dimensions] = features\n",
      "                X_orb.append(features)\n",
      "                Y_orb.append(label)\n",
      "\n",
      "            files.append(nameFileImage)\n",
      "            image = resize(image, (maxPixel, maxPixel))\n",
      "            \n",
      "            # store the rescaled image pixels and the axis ratio\n",
      "            X[i, 0:imageSize] = np.reshape(image, (1, imageSize))\n",
      "            \n",
      "            # height/width ratio feature\n",
      "            axisratio = getMinorMajorRatio(image)\n",
      "            X[i, imageSize] = axisratio\n",
      "            \n",
      "            # corner features\n",
      "            X[i, imageSize+1] = no_of_corners\n",
      "            X[i, imageSize+2] = corners_x_coord_std\n",
      "            X[i, imageSize+3] = corners_y_coord_std\n",
      "            \n",
      "            # Store the classlabel\n",
      "            y[i] = label\n",
      "            i += 1\n",
      "            # report progress for each 5% done  \n",
      "            report = [int((j+1)*num_rows/20.) for j in range(20)]\n",
      "            if i in report: print np.ceil(i *100.0 / num_rows), \"% done\"\n",
      "    label += 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading images and compute features\n",
        "5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "10.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "15.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "20.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "25.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "30.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "35.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "40.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "45.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "50.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "55.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "60.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "65.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "70.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "75.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "80.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "85.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "90.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "95.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n",
        "100.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " % done\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification performance using raw pixel of image as features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 625) (3071,)\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,0:imageSize].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,0:imageSize], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 10.0, 'gamma': 0.10000000000000001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.778162308715\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.91      0.96      0.93       889\n",
        "data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      data/train/acantharia_protist_halo       0.72      0.46      0.56        71\n",
        "                    data/train/amphipods       0.97      0.61      0.75        49\n",
        "data/train/appendicularian_fritillaridae       0.25      0.06      0.10        16\n",
        "      data/train/appendicularian_s_shape       0.73      0.76      0.74       696\n",
        " data/train/appendicularian_slight_curve       0.61      0.62      0.61       532\n",
        "     data/train/appendicularian_straight       0.60      0.49      0.54       242\n",
        "                    data/train/artifacts       0.88      0.90      0.89       393\n",
        "               data/train/artifacts_edge       0.77      0.84      0.80       170\n",
        "\n",
        "                             avg / total       0.77      0.78      0.77      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using height/width ratio of region of interest as feature"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X[:,imageSize:imageSize+1].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X[:,imageSize:imageSize+1], y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1000.0, 'gamma': 1.0}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.441931793708\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.51      0.80      0.62       889\n",
        "data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      data/train/acantharia_protist_halo       0.00      0.00      0.00        71\n",
        "                    data/train/amphipods       0.00      0.00      0.00        49\n",
        "data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      data/train/appendicularian_s_shape       0.36      0.60      0.45       696\n",
        " data/train/appendicularian_slight_curve       0.38      0.23      0.29       532\n",
        "     data/train/appendicularian_straight       0.60      0.21      0.31       242\n",
        "                    data/train/artifacts       0.00      0.00      0.00       393\n",
        "               data/train/artifacts_edge       0.53      0.33      0.41       170\n",
        "\n",
        "                             avg / total       0.37      0.44      0.38      3071\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using raw pixel, height/width ratio, # of corners, \n",
      "and corners x coordinates std, corners y coordinates std features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(X, y, namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using point-based feature (ORB)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(X_orb), len(Y_orb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7 7\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_orb = np.asarray(X_orb)\n",
      "y_orb = np.asarray(Y_orb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computePerformance(x_orb, y_orb, namesClasses, cv_folds=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'kernel': 'rbf', 'C': 1.0, 'gamma': 0.0001}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of all classes\n",
        "0.444444444444\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.50      0.50      0.50         4\n",
        "data/train/acantharia_protist_big_center       0.33      0.33      0.33         3\n",
        "\n",
        "                             avg / total       0.43      0.43      0.43         7\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Classification using SSIM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3071, 625) (3071,)\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.measure import structural_similarity as ssim\n",
      "def sim_ssim(x1, x2, size=25):\n",
      "    # the structural similarity (SSIM) metric measures how similar two images based on their mean, variance, and correlation.\n",
      "    # formula for the index:\n",
      "    # SSIM(x,y) = mean(x,y)^alpha + variance(x,y)^beta + correlation(x,y)^gamma\n",
      "    # good reference for index is here: http://foulard.ece.cornell.edu/dmr58/dmr_icip2008.pdf\n",
      "    image1 = x1.reshape((size,size))\n",
      "    image2 = x2.reshape((size,size))\n",
      "    return ssim(image1, image2)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = list()\n",
      "k_folds = cross_validation.KFold(X.shape[0], n_folds=3)\n",
      "y_pred = y * 0\n",
      "\n",
      "for train_index, test_index in k_folds:\n",
      "    X_train, X_test = X[train_index], X[test_index]\n",
      "    Y_train, Y_test = y[train_index], y[test_index]\n",
      "    \n",
      "    print \"compute similarity matrix as kernel for training set\"\n",
      "    n = len(train_index)\n",
      "    similarity_matrix_train = np.zeros((n, n))\n",
      "    for i in range(0,n):\n",
      "        for j in range(0,n):\n",
      "            similarity_matrix_train[i,j] = sim_ssim(X_train[i], X_train[j])\n",
      "\n",
      "    print \"fit model using similarity matrix\"\n",
      "    svc = SVC(kernel='precomputed')\n",
      "    fit = svc.fit(similarity_matrix_train, Y_train)\n",
      "\n",
      "    print \"compute similarity matrix for test set\"\n",
      "    m = len(test_index)\n",
      "    similarity_matrix_test = np.zeros((m, n))\n",
      "    for i in range(0,m):\n",
      "        for j in range(0,n):\n",
      "            similarity_matrix_test[i,j] = sim_ssim(X_test[i], X_train[j])\n",
      "\n",
      "    print \"compute prediction on test set\"\n",
      "    y_pred[test_index] = fit.predict(similarity_matrix_test)\n",
      "    \n",
      "    print classification_report(y, y_pred, target_names=namesClasses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compute similarity matrix as kernel for training set\n",
        "fit model using similarity matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "compute similarity matrix for test set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "compute prediction on test set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.00      0.00      0.00       889\n",
        "data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      data/train/acantharia_protist_halo       0.00      0.00      0.00        71\n",
        "                    data/train/amphipods       0.00      0.00      0.00        49\n",
        "data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      data/train/appendicularian_s_shape       0.00      0.00      0.00       696\n",
        " data/train/appendicularian_slight_curve       0.00      0.00      0.00       532\n",
        "     data/train/appendicularian_straight       0.00      0.00      0.00       242\n",
        "                    data/train/artifacts       0.00      0.00      0.00       393\n",
        "               data/train/artifacts_edge       0.00      0.00      0.00       170\n",
        "\n",
        "                             avg / total       0.00      0.00      0.00      3071\n",
        "\n",
        "compute similarity matrix as kernel for training set\n",
        "fit model using similarity matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "compute similarity matrix for test set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "compute prediction on test set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                                          precision    recall  f1-score   support\n",
        "\n",
        "           data/train/acantharia_protist       0.00      0.00      0.00       889\n",
        "data/train/acantharia_protist_big_center       0.00      0.00      0.00        13\n",
        "      data/train/acantharia_protist_halo       0.00      0.00      0.00        71\n",
        "                    data/train/amphipods       0.00      0.00      0.00        49\n",
        "data/train/appendicularian_fritillaridae       0.00      0.00      0.00        16\n",
        "      data/train/appendicularian_s_shape       0.00      0.00      0.00       696\n",
        " data/train/appendicularian_slight_curve       0.29      0.40      0.33       532\n",
        "     data/train/appendicularian_straight       0.00      0.00      0.00       242\n",
        "                    data/train/artifacts       0.00      0.00      0.00       393\n",
        "               data/train/artifacts_edge       0.00      0.00      0.00       170\n",
        "\n",
        "                             avg / total       0.05      0.07      0.06      3071\n",
        "\n",
        "compute similarity matrix as kernel for training set\n",
        "fit model using similarity matrix"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "compute similarity matrix for test set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "compute prediction on test set"
       ]
      }
     ],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}